<!DOCTYPE html>
<html lang="es">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Demo UI Generativa - Biometr칤a</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
      background-color: #f0f2f5;
      transition: background-color 0.5s ease;
    }

    /* Contenedor principal */
    .container {
      text-align: center;
      position: relative;
    }

    /* Video de la webcam (lo mostramos peque침o para feedback) */
    #video {
      width: 320px;
      height: 240px;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      margin-bottom: 20px;
      transform: scaleX(-1);
      /* Efecto espejo */
    }

    /* La UI Card que cambia */
    .ui-card {
      background: white;
      padding: 40px;
      border-radius: 24px;
      box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
      width: 400px;
      transition: all 0.5s cubic-bezier(0.25, 0.8, 0.25, 1);
      border: 2px solid transparent;
    }

    .ui-card h1 {
      margin: 0 0 10px 0;
      font-size: 2rem;
    }

    .ui-card p {
      font-size: 1.2rem;
      color: #555;
      margin: 0;
    }

    /* Estados de la UI */
    .ui-card.neutral {
      border-color: #3498db;
      background-color: #eaf6ff;
    }

    .ui-card.neutral h1 {
      color: #2980b9;
    }

    .ui-card.happy {
      border-color: #2ecc71;
      background-color: #eafaf1;
      transform: scale(1.05);
    }

    .ui-card.happy h1 {
      color: #27ae60;
    }

    .ui-card.sad {
      /* Usamos 'sad' para ce침o fruncido/tensi칩n */
      border-color: #e74c3c;
      background-color: #fdedec;
    }

    .ui-card.sad h1 {
      color: #c0392b;
    }

    /* Estado de carga */
    #status {
      margin-top: 20px;
      color: #777;
      font-style: italic;
    }
  </style>
</head>

<body>

  <div class="container">
    <!-- Video oculto hasta que cargue -->
    <video id="video" autoplay muted playsinline></video>

    <div id="ui-card" class="ui-card neutral">
      <h1>Esperando rostro...</h1>
      <p>Iniciando sistema de biometr칤a...</p>
    </div>

    <div id="status">Cargando modelos...</div>
  </div>

  <!-- Cargar face-api.js desde CDN para asegurar integridad -->
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

  <script>
    const video = document.getElementById('video');
    const uiCard = document.getElementById('ui-card');
    const statusText = document.getElementById('status');
    const cardTitle = uiCard.querySelector('h1');
    const cardDesc = uiCard.querySelector('p');

    // Configuraci칩n
    const MODEL_URL = './models';

    async function loadModels() {
      try {
        statusText.innerText = "Cargando Tiny Face Detector...";
        await faceapi.loadTinyFaceDetectorModel(MODEL_URL);

        statusText.innerText = "Cargando Face Landmark 68...";
        await faceapi.loadFaceLandmarkModel(MODEL_URL);

        statusText.innerText = "Cargando Face Expression...";
        await faceapi.loadFaceExpressionModel(MODEL_URL);

        startVideo();
      } catch (err) {
        console.error("Error cargando modelos:", err);
        statusText.innerText = "Error: " + err.message;
      }
    }

    loadModels();

    // 2. Iniciar video
    function startVideo() {
      statusText.innerText = "Solicitando c치mara...";
      navigator.mediaDevices.getUserMedia({ video: {} })
        .then(stream => {
          video.srcObject = stream;
          statusText.innerText = "Detectando...";
        })
        .catch(err => {
          console.error(err);
          statusText.innerText = "Error accediendo a la c치mara.";
        });
    }

    // 3. Loop de detecci칩n
    video.addEventListener('play', () => {
      setInterval(async () => {
        // Detectar rostro y expresiones
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceExpressions();

        if (detections.length > 0) {
          // Tomamos la primera cara detectada
          const expressions = detections[0].expressions;

          // Buscamos la expresi칩n dominante
          const dominant = Object.keys(expressions).reduce((a, b) => expressions[a] > expressions[b] ? a : b);

          updateUI(dominant);
        } else {
          // Si no hay cara, volver a neutral o estado de espera
          updateUI('neutral');
        }
      }, 200); // Ejecutar cada 200ms para no saturar
    });

    // 4. Actualizar UI seg칰n expresi칩n
    function updateUI(expression) {
      // Limpiar clases previas
      uiCard.classList.remove('neutral', 'happy', 'sad');

      switch (expression) {
        case 'happy':
          uiCard.classList.add('happy');
          cardTitle.innerText = "游뗵 Est치s sonriendo";
          cardDesc.innerText = "Generando UI positiva y vibrante.";
          break;

        case 'sad':
        case 'angry':
        case 'disgusted':
        case 'fearful':
          // Agrupamos expresiones negativas
          uiCard.classList.add('sad');
          cardTitle.innerText = "游 Detecto tensi칩n";
          cardDesc.innerText = "Adaptando UI para reducir carga cognitiva.";
          break;

        case 'neutral':
        case 'surprised':
        default:
          uiCard.classList.add('neutral');
          cardTitle.innerText = "游땛 Estado neutral";
          cardDesc.innerText = "Interfaz estable y balanceada.";
          break;
      }
    }
  </script>
</body>

</html>